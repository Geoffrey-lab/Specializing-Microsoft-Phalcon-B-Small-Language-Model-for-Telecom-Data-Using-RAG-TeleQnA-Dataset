# Specializing-Microsoft-Phalcon-B-Small-Language-Model-for-Telecom-Data-Using-RAG-TeleQnA-Dataset
This repository contains notebooks and code for specializing the Microsoft Phalcon-B Small Language Model to telecom data using Retrieval-Augmented Generation (RAG) and the TeleQnA dataset. This project is part of the ITU AI/ML in 5G Challenge and aims to enhance data processing and question answering in the telecommunications domain.

Contents
Notebooks: Detailed steps for preprocessing the TeleQnA dataset, fine-tuning the Phalcon-B model, and implementing the RAG framework.
Data Handling: Scripts for cleaning, handling missing data, and preparing the dataset for training and evaluation.
Model Training: Code for training the Phalcon-B model with telecom-specific data and fine-tuning using the TeleQnA dataset.
Evaluation Metrics: Methods to evaluate the model's performance on telecom-related questions.
Submission Generation: Scripts to generate submission files for the ITU AI/ML in 5G Challenge, ensuring compliance with the challenge requirements.
Random Answer Adjustment: Code to randomly adjust answer IDs in the submission file to introduce variability for testing purposes.
Getting Started
Clone the Repository:

bash
Copy code
git clone https://github.com/your-username/Phalcon-B-Telecom-Specialization.git
cd Phalcon-B-Telecom-Specialization
Install Dependencies:
Ensure you have the necessary Python packages installed. You can use requirements.txt to install them:

bash
Copy code
pip install -r requirements.txt
Data Preparation:
Follow the instructions in the notebooks to preprocess the TeleQnA dataset and prepare it for training.

Model Training:
Use the provided notebooks to fine-tune the Phalcon-B model using the RAG framework with the prepared dataset.

Evaluation:
Evaluate the model's performance using the provided scripts and metrics.

Generate Submission:
Use the scripts to generate submission files for the ITU AI/ML in 5G Challenge, ensuring all questions are answered correctly.

Contributions
Contributions are welcome! If you have any improvements or new features to add, feel free to open a pull request or submit an issue.

License
This project is licensed under the MIT License - see the LICENSE file for details.


